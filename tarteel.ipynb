{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_MQwxDghI4SE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "A file for creating a one-hot encoding of all characters, including madd and harakat, in Tarteel's Qur'an dataset.\n",
        "\n",
        "The output pickle file will contain an object with the one-hot encoded Qur'an, an encoding function, and a decoding\n",
        "function.\n",
        "\n",
        "Author: Hamzah Khan\n",
        "Date: Jan. 12, 2019\n",
        "\"\"\"\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "import dill as pickle\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "parser = ArgumentParser(description='Tarteel Arabic One Hot Encoding Generator')\n",
        "parser.add_argument('-i', '--input_json_path', type=str)\n",
        "parser.add_argument('-o', '--output_pickle_path', type=str)\n",
        "parser.add_argument('-v', '--verbose', type=bool, default=False)\n",
        "args = parser.parse_args(['-i', 'data-uthmani.json', '-o', 'one-hot.pkl']) # You will need to replace input.json and output.pickle with the actual paths to your input and output files\n",
        "\n",
        "# Define constants.\n",
        "QURAN_KEY  = \"quran\"\n",
        "SURAHS_KEY = \"surahs\"\n",
        "AYAHS_KEY  = \"ayahs\"\n",
        "TEXT_KEY   = \"text\"\n",
        "\n",
        "NUM_KEY       = \"num\"\n",
        "NAME_KEY      = \"name\"\n",
        "BISMILLAH_KEY = \"bismillah\"\n",
        "\n",
        "ENCODING_MAP_KEY = \"encoding_map\"\n",
        "DECODING_MAP_KEY = \"decoding_map\"\n",
        "CHAR_TO_INT_MAP_KEY = \"char_to_int\"\n",
        "INT_TO_CHAR_MAP_KEY = \"int_to_char\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Bbqyv_CLOjr7"
      },
      "outputs": [],
      "source": [
        "def create_list_of_quranic_chars(quran_obj, surahs_key=SURAHS_KEY, ayahs_key=AYAHS_KEY, text_key=TEXT_KEY):\n",
        "    \"\"\"\n",
        "    Create a sorted list containing every character in the Qur'an text provided and return it.\n",
        "    :param quran_obj: An object containing surah objects.\n",
        "    :type quran_obj: object\n",
        "    :param surahs_key: The key in quran_obj to the list of surah objects.\n",
        "    :type surahs_key: string\n",
        "    :param ayahs_key: The key in each surah object to the list of ayah objects in that surah.\n",
        "    :type ayahs_key: string\n",
        "    :param text_key: The key to the actual Qur'anic text in each ayah object.\n",
        "    :type text_key: string\n",
        "    :returns: A sorted list containing every Arabic character in the Qur'an exactly once.\n",
        "    :rtype: list string\n",
        "    \"\"\"\n",
        "    quranic_char_set = set()\n",
        "\n",
        "    for surah_obj in quran_obj[surahs_key]:\n",
        "        for ayah_obj in surah_obj[ayahs_key]:\n",
        "            ayah_text = ayah_obj[text_key]\n",
        "\n",
        "            for char in ayah_text:\n",
        "                quranic_char_set.add(char)\n",
        "\n",
        "    return sorted(list(quranic_char_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "OiKsnVPfM2-H"
      },
      "outputs": [],
      "source": [
        "def encode_char_as_one_hot(string, char_to_int):\n",
        "    \"\"\"\n",
        "    Converts a string of characters from our alphabet into a one_hot encoded string.\n",
        "    \"\"\"\n",
        "    str_len = len(string)\n",
        "    int_list = np.array([char_to_int[char] for char in string])\n",
        "\n",
        "    one_hot_string = np.zeros((str_len, len(char_to_int)))\n",
        "    one_hot_string[np.arange(str_len), int_list] = 1\n",
        "\n",
        "    return one_hot_string\n",
        "\n",
        "def create_one_hot_encoding(quranic_char_list):\n",
        "    \"\"\"\n",
        "    Creates a one-hot encoding that associates each character in the argument list to a number and vice versa.\n",
        "    :param quranic_char_list: A list of characters.\n",
        "    :type quranic_char_list: list string\n",
        "    :returns: A tuple containing the encoding and decoding functions for the alphabet.\n",
        "    :rtype: tuple (function string => int, function int => string)\n",
        "    \"\"\"\n",
        "\n",
        "    # Define an encoding of characters to integers.\n",
        "    char_to_int = dict((c, i) for i, c in enumerate(quranic_char_list))\n",
        "    int_to_char = dict((i, c) for i, c in enumerate(quranic_char_list))\n",
        "\n",
        "    print('quranic_char_list: ', quranic_char_list)\n",
        "\n",
        "    print(\"char_to_int: \", char_to_int)\n",
        "    print(\"int_to_char: \", int_to_char)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def decode_one_hot_as_string(one_hot_string, int_to_char):\n",
        "        \"\"\"\n",
        "        Converts a one_hot encoded numpy array back into a string of characters from our alphabet.\n",
        "        \"\"\"\n",
        "        int_list = list(np.argmax(one_hot_string, axis=1))\n",
        "        char_list = [int_to_char[integer] for integer in int_list]\n",
        "\n",
        "        return str(char_list)\n",
        "\n",
        "    return char_to_int, int_to_char, encode_char_as_one_hot, decode_one_hot_as_string\n",
        "\n",
        "\n",
        "def generate_a_one_hot_encoded_script(quran_obj,\n",
        "                                      encoding_fn,\n",
        "                                      surahs_key=SURAHS_KEY,\n",
        "                                      ayahs_key=AYAHS_KEY,\n",
        "                                      text_key=TEXT_KEY,\n",
        "                                      num_key=NUM_KEY,\n",
        "                                      name_key=NAME_KEY,\n",
        "                                      bismillah_key=BISMILLAH_KEY):\n",
        "    \"\"\"\n",
        "    Translates each ayah in the given quran_obj into a vector of one-hot encoded characters using the given encoding.\n",
        "    Create a sorted list containing every character in the Qur'an text provided and return it.\n",
        "    :param quran_obj: An object containing surah objects.\n",
        "    :type quran_obj: object\n",
        "    :param quran_obj: A function that converts Arabic Qur'anic characters to a one-hot encoding.\n",
        "    :type quran_obj: function (Arabic string => numpy 2darray)\n",
        "    :param surahs_key: The key in quran_obj to the list of surah objects.\n",
        "    :type surahs_key: string\n",
        "    :param ayahs_key: The key in each surah object to the list of ayah objects in that surah.\n",
        "    :type ayahs_key: string\n",
        "    :param text_key: The key to the actual Qur'anic text in each ayah object.\n",
        "    :type text_key: string\n",
        "    :param num_key: The key in surah and ayah objects to the ordering of the surah or ayah.\n",
        "    :type num_key: string\n",
        "    :param name_key: The key in each surah object to the name of that surah.\n",
        "    :type name_key: string\n",
        "    :param bismillah_key: The key to the bismillah text in the first ayah object of each surah object.\n",
        "    :type bismillah_key: string\n",
        "    :returns: An object identical to the quran_obj but with one-hot encodings of all Arabic text (not names).\n",
        "    :rtype: object\n",
        "    \"\"\"\n",
        "    one_hot_quran_encoding = {}\n",
        "    one_hot_quran_encoding[SURAHS_KEY] = []\n",
        "\n",
        "    for surah_obj in quran_obj[surahs_key]:\n",
        "        # Copy new surah object for one-hot Json container.\n",
        "        one_hot_surah_obj            = {}\n",
        "        one_hot_surah_obj[num_key]   = surah_obj[num_key]\n",
        "        one_hot_surah_obj[name_key]  = surah_obj[name_key]\n",
        "        one_hot_surah_obj[ayahs_key] = []\n",
        "\n",
        "        for ayah_obj in surah_obj[ayahs_key]:\n",
        "            ayah_text = ayah_obj[text_key]\n",
        "\n",
        "            # Make new ayah object for one-hot Json container.\n",
        "            one_hot_ayah_obj           = {}\n",
        "            one_hot_ayah_obj[num_key]  = ayah_obj[num_key]\n",
        "            one_hot_ayah_obj[text_key] = encoding_fn(ayah_text)\n",
        "\n",
        "            if bismillah_key in ayah_obj:\n",
        "                one_hot_ayah_obj[bismillah_key] = encoding_fn(ayah_obj[bismillah_key])\n",
        "\n",
        "            one_hot_surah_obj[ayahs_key].append(one_hot_ayah_obj)\n",
        "        one_hot_quran_encoding[surahs_key].append(one_hot_surah_obj)\n",
        "\n",
        "    return one_hot_quran_encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# try:\n",
        "with open(args.input_json_path, 'rb') as quran_json_file:\n",
        "\n",
        "    # Import json file.\n",
        "    quran_obj = json.load(quran_json_file)[QURAN_KEY]\n",
        "#\n",
        "# except:\n",
        "#     print(\"Json file failed to open. Exiting script...\")\n",
        "#     return\n",
        "\n",
        "# Get the list of every character in the Qur'an.\n",
        "quranic_char_list = create_list_of_quranic_chars(quran_obj)\n",
        "\n",
        "if args.verbose:\n",
        "    print(quranic_char_list, ' has ', len(quranic_char_list), ' characters.')\n",
        "\n",
        "encode_char_as_one_hot(\"بسم الله الرحمن الرحيم\", dict((c, i) for i, c in enumerate(quranic_char_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "IfAMl-eROryQ"
      },
      "outputs": [],
      "source": [
        "def run_script(args):\n",
        "    \"\"\"\n",
        "    Runs the script to find all characters, generate the encoding, and translate and store it in the output file.\n",
        "    \"\"\"\n",
        "    # try:\n",
        "    with open(args.input_json_path, 'rb') as quran_json_file:\n",
        "\n",
        "        # Import json file.\n",
        "        quran_obj = json.load(quran_json_file)[QURAN_KEY]\n",
        "    #\n",
        "    # except:\n",
        "    #     print(\"Json file failed to open. Exiting script...\")\n",
        "    #     return\n",
        "\n",
        "    # Get the list of every character in the Qur'an.\n",
        "    quranic_char_list = create_list_of_quranic_chars(quran_obj)\n",
        "\n",
        "    if args.verbose:\n",
        "        print(quranic_char_list, ' has ', len(quranic_char_list), ' characters.')\n",
        "\n",
        "    # Create the one-hot encodings.\n",
        "    char_to_int_map, \\\n",
        "    int_to_char_map, \\\n",
        "    encode_char_as_one_hot, \\\n",
        "    decode_one_hot_as_string = create_one_hot_encoding(quranic_char_list)\n",
        "\n",
        "    if args.verbose:\n",
        "        print(\"encode!\")\n",
        "        x = encode_char_as_one_hot(\"\".join(quranic_char_list))\n",
        "        print(x)\n",
        "        print(\"decode!\")\n",
        "        print(decode_one_hot_as_string(x))\n",
        "\n",
        "    # Generate the Qur'anic text in one-hot encoding.\n",
        "    one_hot_quran_encoding = generate_a_one_hot_encoded_script(\n",
        "        quran_obj,\n",
        "        lambda string: encode_char_as_one_hot(string, char_to_int_map))\n",
        "\n",
        "    # Create an object with the encoding and the two functions.\n",
        "    full_object = {\n",
        "        QURAN_KEY: one_hot_quran_encoding,\n",
        "        ENCODING_MAP_KEY: encode_char_as_one_hot,\n",
        "        DECODING_MAP_KEY: decode_one_hot_as_string,\n",
        "        CHAR_TO_INT_MAP_KEY: char_to_int_map,\n",
        "        INT_TO_CHAR_MAP_KEY: int_to_char_map\n",
        "    }\n",
        "\n",
        "    with open(args.output_pickle_path, 'wb') as one_hot_quran_pickle_file:\n",
        "        pickle.dump(full_object, one_hot_quran_pickle_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "KPBN_1Y9OvNM"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "quranic_char_list:  [' ', 'ء', 'أ', 'ؤ', 'إ', 'ئ', 'ا', 'ب', 'ة', 'ت', 'ث', 'ج', 'ح', 'خ', 'د', 'ذ', 'ر', 'ز', 'س', 'ش', 'ص', 'ض', 'ط', 'ظ', 'ع', 'غ', 'ـ', 'ف', 'ق', 'ك', 'ل', 'م', 'ن', 'ه', 'و', 'ى', 'ي', 'ً', 'ٌ', 'ٍ', 'َ', 'ُ', 'ِ', 'ّ', 'ْ', 'ٓ', 'ٔ', 'ٰ', 'ٱ', 'ۜ', '۟', 'ۢ', 'ۣ', 'ۥ', 'ۦ', 'ۨ', '۪', '۫', '۬']\n",
            "char_to_int:  {' ': 0, 'ء': 1, 'أ': 2, 'ؤ': 3, 'إ': 4, 'ئ': 5, 'ا': 6, 'ب': 7, 'ة': 8, 'ت': 9, 'ث': 10, 'ج': 11, 'ح': 12, 'خ': 13, 'د': 14, 'ذ': 15, 'ر': 16, 'ز': 17, 'س': 18, 'ش': 19, 'ص': 20, 'ض': 21, 'ط': 22, 'ظ': 23, 'ع': 24, 'غ': 25, 'ـ': 26, 'ف': 27, 'ق': 28, 'ك': 29, 'ل': 30, 'م': 31, 'ن': 32, 'ه': 33, 'و': 34, 'ى': 35, 'ي': 36, 'ً': 37, 'ٌ': 38, 'ٍ': 39, 'َ': 40, 'ُ': 41, 'ِ': 42, 'ّ': 43, 'ْ': 44, 'ٓ': 45, 'ٔ': 46, 'ٰ': 47, 'ٱ': 48, 'ۜ': 49, '۟': 50, 'ۢ': 51, 'ۣ': 52, 'ۥ': 53, 'ۦ': 54, 'ۨ': 55, '۪': 56, '۫': 57, '۬': 58}\n",
            "int_to_char:  {0: ' ', 1: 'ء', 2: 'أ', 3: 'ؤ', 4: 'إ', 5: 'ئ', 6: 'ا', 7: 'ب', 8: 'ة', 9: 'ت', 10: 'ث', 11: 'ج', 12: 'ح', 13: 'خ', 14: 'د', 15: 'ذ', 16: 'ر', 17: 'ز', 18: 'س', 19: 'ش', 20: 'ص', 21: 'ض', 22: 'ط', 23: 'ظ', 24: 'ع', 25: 'غ', 26: 'ـ', 27: 'ف', 28: 'ق', 29: 'ك', 30: 'ل', 31: 'م', 32: 'ن', 33: 'ه', 34: 'و', 35: 'ى', 36: 'ي', 37: 'ً', 38: 'ٌ', 39: 'ٍ', 40: 'َ', 41: 'ُ', 42: 'ِ', 43: 'ّ', 44: 'ْ', 45: 'ٓ', 46: 'ٔ', 47: 'ٰ', 48: 'ٱ', 49: 'ۜ', 50: '۟', 51: 'ۢ', 52: 'ۣ', 53: 'ۥ', 54: 'ۦ', 55: 'ۨ', 56: '۪', 57: '۫', 58: '۬'}\n"
          ]
        }
      ],
      "source": [
        "def load_data(pickle_file):\n",
        "    \"\"\"\n",
        "    A sample function to demonstrate how to load the object.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(pickle_file, 'rb') as one_hot_pickle:\n",
        "            one_hot_obj = pickle.load(one_hot_pickle)\n",
        "\n",
        "            print('Now, we can do things with it! Keys: ', one_hot_obj.keys())\n",
        "\n",
        "    except:\n",
        "        print(\"Pickle file failed to open. Exiting...\")\n",
        "        return\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_script(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "collapsed": true,
        "id": "CxeW6C4-PqyE",
        "outputId": "1eeb018f-3dbe-4a1b-f168-c9ecb0addcde"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    with open('one-hot.pkl', 'rb') as one_hot_pickle:\n",
        "        one_hot_obj = pickle.load(one_hot_pickle)\n",
        "except:\n",
        "    print(\"Pickle file failed to open. Exiting...\")\n",
        "\n",
        "\n",
        "one_hot_quran    = one_hot_obj[QURAN_KEY]\n",
        "str_to_onehot_fn = one_hot_obj[ENCODING_MAP_KEY]\n",
        "onehot_to_str_fn = one_hot_obj[DECODING_MAP_KEY]\n",
        "char_to_int_map  = one_hot_obj[CHAR_TO_INT_MAP_KEY]\n",
        "int_to_char_map  = one_hot_obj[INT_TO_CHAR_MAP_KEY]\n",
        "\n",
        "encoding_fn = lambda string: str_to_onehot_fn(string, char_to_int_map)\n",
        "decoding_fn = lambda one_hot: onehot_to_str_fn(one_hot, int_to_char_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6hzLIR5bPqvD"
      },
      "outputs": [],
      "source": [
        "def get_verse_in_quran_obj(one_hot_quran, surah_num, ayah_num):\n",
        "    \"\"\"\n",
        "    Looks up and returns the (encoded or decoded) string in the quran object.\n",
        "    \"\"\"\n",
        "    return one_hot_quran[SURAHS_KEY][surah_num][AYAHS_KEY][ayah_num][TEXT_KEY]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKKvLe13du_M",
        "outputId": "c016fba5-3370-4cc6-9fc0-d93c84bd4752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ذ', 'َ', 'ٰ', 'ل', 'ِ', 'ك', 'َ', ' ', 'ٱ', 'ل', 'ْ', 'ك', 'ِ', 'ت', 'َ', 'ٰ', 'ب', 'ُ', ' ', 'ل', 'َ', 'ا', ' ', 'ر', 'َ', 'ي', 'ْ', 'ب', 'َ', ' ', 'ف', 'ِ', 'ي', 'ه', 'ِ', ' ', 'ه', 'ُ', 'د', 'ً', 'ى', ' ', 'ل', 'ّ', 'ِ', 'ل', 'ْ', 'م', 'ُ', 'ت', 'ّ', 'َ', 'ق', 'ِ', 'ي', 'ن', 'َ']\n"
          ]
        }
      ],
      "source": [
        "one_hot_ayah = get_verse_in_quran_obj(one_hot_quran, 1, 1)\n",
        "string_ayah = decoding_fn(one_hot_ayah)\n",
        "print(string_ayah)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EsE7vnT7PqsN"
      },
      "outputs": [],
      "source": [
        "split_unique_ayahs = True\n",
        "ayah_nums = []\n",
        "if split_unique_ayahs:\n",
        "    unique_ayahs = defaultdict(list)\n",
        "    for surah_num in range(1):\n",
        "        for ayah_num in range(len(one_hot_quran[SURAHS_KEY][surah_num][AYAHS_KEY])):\n",
        "            one_hot_ayah = get_verse_in_quran_obj(one_hot_quran, surah_num, ayah_num)\n",
        "            string_ayah = decoding_fn(one_hot_ayah)\n",
        "            unique_ayahs[string_ayah].append((surah_num, ayah_num))\n",
        "\n",
        "    for ayah_string in unique_ayahs:\n",
        "        identical_ayah_list = unique_ayahs[ayah_string]\n",
        "        ayah_nums.append(identical_ayah_list)\n",
        "\n",
        "else:\n",
        "    for surah_num in range(1):\n",
        "        for ayah_num in range(len(one_hot_quran[SURAHS_KEY][surah_num][AYAHS_KEY])):\n",
        "            ayah_nums.append(ayah_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPNF0av8fCEW",
        "outputId": "958f4439-6a88-450d-cff2-a78f9a3c3931"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[(0, 0)], [(0, 1)], [(0, 2)], [(0, 3)], [(0, 4)], [(0, 5)], [(0, 6)]]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ayah_nums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5FzURodf1vI",
        "outputId": "4d667de7-9ab3-4563-d5a5-b4118fc07b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[(0, 5)], [(0, 1)], [(0, 3)]]\n",
            "[[(0, 6)], [(0, 2)]]\n",
            "[[(0, 4)], [(0, 0)]]\n"
          ]
        }
      ],
      "source": [
        "# This gives us a 60-20-20 split.\n",
        "RANDOM_SEED = 1\n",
        "TRAIN_SPLIT = 0.6\n",
        "TEST_SPLIT  = 0.2\n",
        "VALIDATION_SPLIT = 0.2\n",
        "# Logic for splits\n",
        "split1_percent = TRAIN_SPLIT + VALIDATION_SPLIT\n",
        "split2_percent = 1.0 - (VALIDATION_SPLIT / split1_percent)\n",
        "\n",
        "X_train_valid, X_test = train_test_split(ayah_nums,\n",
        "                                          train_size=split1_percent,\n",
        "                                          random_state=RANDOM_SEED,\n",
        "                                          shuffle=True)\n",
        "X_train, X_valid = train_test_split(X_train_valid,\n",
        "                                    train_size=split2_percent,\n",
        "                                    random_state=RANDOM_SEED,\n",
        "                                    shuffle=True)\n",
        "print(X_train)\n",
        "print(X_test)\n",
        "print(X_valid)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
